_wandb:
    value:
        cli_version: 0.20.1
        code_path: code/Code/PPO_Optimisation_2/Streamline/Actor_Critic_CleanRL.py
        m:
            - "1": training/action
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": global_step
              "6": []
              "7": []
            - "1": training/reward
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": training/value
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": training/entropy
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": charts/learning_rate
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": charts/episodic_return
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": charts/episodic_length
              "5": 2
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.13.0
        t:
            "1":
                - 1
                - 77
            "2":
                - 1
                - 77
            "3":
                - 1
                - 7
                - 13
                - 16
                - 35
                - 55
            "4": 3.13.0
            "5": 0.20.1
            "8":
                - 3
            "12": 0.20.1
            "13": windows-amd64
anneal_lr:
    value: true
capture_video:
    value: false
clip_coef:
    value: 0.2
cuda:
    value: true
ent_coef:
    value: 0.01
env_id:
    value: PPOEnv
exp_name:
    value: Actor_Critic_CleanRL
gae_lambda:
    value: 0.95
gamma:
    value: 0.9
learning_rate:
    value: 0.0003
max_grad_norm:
    value: 0.5
norm_adv:
    value: true
num_envs:
    value: 1
num_minibatches:
    value: 16
num_steps:
    value: 431
seed:
    value: 1
target_kl:
    value: null
torch_deterministic:
    value: true
total_timesteps:
    value: 50000
track:
    value: true
update_epochs:
    value: 5
vf_coef:
    value: 0.5
wandb_entity:
    value: null
wandb_project_name:
    value: cleanrl-gnn-wntr
